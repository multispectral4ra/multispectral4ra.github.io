
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="keywords" content="accv, workshop, computer vision, multispectral camera, autonomous driving, sensors, machine learning">

  <link rel="shortcut icon" href="static/img/site/favicon_mira2.ico">

  <title>ACCV2024 Workshop on Multispectral Imaging for Robotics and Automation (MIRA)</title>
  <meta name="description" content="Use of multispectral cameras for robotics and automation, ACCV 2024 Workshop">

  <!--Open Graph Related Stuff-->
  <meta property="og:title" content="Workshop on Multispectral Imaging for Robotics and Automation (MIRA)"/>
  <meta property="og:url" content="https://multispectral4ra.github.io/"/>
  <meta property="og:description" content="Use of multispectral cameras for robotics and automation, ACCV 2024 Workshop"/>
  <meta property="og:site_name" content="Workshop on Multispectral Imaging for Robotics and Automation (MIRA)"/>
  <meta property="og:image" content="https://multispectral4ra.github.io/static/img/site/cover.png"/>

  <!--Twitter Card Stuff-->
  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:title" content="Workshop on Multispectral Imaging for Robotics and Automation (MIRA)"/>
  <meta name="twitter:image" content="https://multispectral4ra.github.io/static/img/site/cover.png">
  <meta name="twitter:url" content="https://multispectral4ra.github.io/"/>
  <meta name="twitter:description" content="Use of multispectral cameras for robotics and automation, ACCV 2024 Workshop"/>

  <!-- CSS  -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet" href="static/css/main.css" media="screen,projection">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

  <style>

    .people-pic {
      max-width: 125px;
      max-height: 125px;
      /*width:300px;*/
      /*height:300px;*/
      object-fit: cover;
      border-radius: 50%;
  }
  </style>

</head>

  <body>

    <!-- <div class="top-strip"></div> -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    
    <div class="navbar-header">
      <a class="navbar-brand" href="/"></a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>

    <div class="navbar-collapse collapse" id="navbar-main">
      <ul class="nav navbar-nav">
        <li><a href="#title" class="scroll-link">Introduction</a></li>
        <li><a href="#cfp" class="scroll-link">Call for papers</a></li>
        <li><a href="#speakers" class="scroll-link">Invited Speakers</a></li>
        <li><a href="#accepted" class="scroll-link">Accepted Papers</a></li>
        <li><a href="#schedule" class="scroll-link">Schedule</a></li>
        <li><a href="#organizers" class="scroll-link">Organizers</a></li>
        <li><a href="#contact" class="scroll-link">Contact</a></li>
      </ul>
    </div>

  </div>
</div>

<script>
  const scrollLinks = document.querySelectorAll('.scroll-link');
  const headerOffset = 80; // Height of the fixed header or any other offset you need

  scrollLinks.forEach(link => {
    link.addEventListener('click', (e) => {
      e.preventDefault();
      const targetId = e.target.getAttribute('href');
      const targetElement = document.querySelector(targetId);

      const elementPosition = targetElement.getBoundingClientRect().top;
      const offsetPosition = elementPosition + window.pageYOffset - headerOffset;

      window.scrollTo({
        top: offsetPosition,
        behavior: 'smooth'
      });
    });
  });
</script>



    <div class="container">
      <div class="page-content">
          <p><br /></p>
<div class="row" id="title">
  <div class="col-xs-12">
    <center><h1>Workshop on <br>Multispectral Imaging for Robotics and Automation <br>(MIRA)</h1></center>
    <center><h2>co-located with <a style="color: #22296d; font-weight:bold;" href="https://www.accv2024.org/"> ACCV 2024</a> and <a style="color: #5a5ca9; font-weight:bold;" href="https://www.acml-conf.org/2024/">ACML 2024</a></h2></center>
    <center><h3>Hanoi, Vietnam - December 8th, 2024</h3></center>
  </div>
</div>

<hr />

<!--
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Past Workshops <span class="caret"></span></a>
  <ul class="dropdown-menu">
    <li><a href="../ACCV2022/index.html" target="__blank">ACCV 2022</a></li>
  </ul>
</li>
-->

<!-- <br>
  <center>
  <h1 style="color:red"><a href="https://www.youtube.com/">The <b>video recording</b> of this workshop is here!</a></h1>
  </center>
<br> -->

<!-- 
<div class="alert alert-info" role="alert">
  <b>For online participation Join the Zoom Meeting from <a href="http://stl.yonsei.ac.kr/">here</a>.</b>
</div>
-->


<div class="row" id="teaser">  
    <div>  
    <img src="static/img/site/miraw_cover.png" style="width: 100%; height: auto;"/>
  </div>
</div>



<p><br /></p>
<div class="row" id="intro">
  <div class="col-xs-12">
    <h2>Introduction</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      Multispectral imaging is revolutionizing the fields of robotics and automation by providing richer information beyond the visible spectrum. Traditional RGB cameras capture only a narrow band of the electromagnetic spectrum, limiting the data available for computer vision systems. Multispectral cameras expand this capability by sensing light across a broader range of wavelengths, including infrared, ultraviolet, and other portions of the spectrum invisible to the human eye.
      <br><br>
      This additional spectral information unlocks powerful new applications in robotics and automation. Multispectral data can be used for enhanced material classification, detecting various objects, identifying chemical signatures, and perceiving environmental factors like moisture and temperature. Additionally, in autonomous driving, multispectral imaging allows vehicles to detect lane markings better, read traffic signals, and identify obstacles in challenging conditions like adverse weather situations and darkness. Such capabilities have transformative potential for industrial inspection, agricultural automation, search and rescue operations, self-driving cars, and countless other domains.
      <br><br>
      The Multispectral Imaging for Robotics and Automation (MIRA) workshop aims to bring together leading researchers exploring this emerging interdisciplinary area at the intersection of multispectral imaging, computer vision, robotics, and automation. 
      <br><br>
      Join us to discuss the latest breakthroughs, share cutting-edge research, and forge new collaborations driving innovation in this exciting field.
    </p>
  </div>
</div>

<p><br /></p>

<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Call For Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
      <p>
        We invite researchers and practitioners to submit original and unpublished work to the Multispectral Imaging for Robotics and Automation (MIRA) workshop. Relevant topics include but are not limited to:
      </p>
      <ul>
        <li>Multispectral image acquisition and sensor fusion</li>
        <li>Multispectral object detection, tracking, and segmentation</li>
        <li>Industrial inspection with multispectral vision</li>
        <li>Agricultural monitoring and automation</li>
        <li>Non-line-of-sight imaging for autonomous vehicles</li>
        <li>Multispectral perception for adverse weather conditions</li>
        <li>Novel applications of multispectral data in robotics and automation</li>
        <li>Multispectral image reconstruction</li>
        <li>Spectral unmixing and material classification</li>
        <li>Domain adaptation and transfer learning for multispectral data</li>
        <li>Multispectral dataset curation and benchmarking</li>
      </ul>
      <p>
        <u>Paper Submission Guidelines:</u>
        <br> 
        To submit papers for consideration, please utilize the workshop's CMT website: <a style="color:#1a1aff;font-weight:400;" href="https://cmt3.research.microsoft.com/MIRA2024">https://cmt3.research.microsoft.com/MIRA2024.</a>  All submissions should be in PDF format.
        <br> 
        Papers that have been previously published or are currently under review elsewhere will not be accepted. It is imperative that submissions adhere to the formatting standards outlined by the Asian Conference on Computer Vision (ACCV), which can be found at <a style="color:#1a1aff;font-weight:400;" href="https://accv2024.org/author-guidelines/">https://accv2024.org/author-guidelines/.</a>
        <br>
        For consistency, papers must use the ACCV LaTeX template and should not exceed 14 pages, including figures and tables. However, additional pages are permissible solely for references.
        <br>
        You can access the official ACCV LaTeX template files by cloning the template from this <a style="color:#1a1aff;font-weight:400;" href="https://www.overleaf.com/read/xzbzbmyfrjks#04841c">overleaf project</a> or downloading this <a style="color:#1a1aff;font-weight:400;" href="https://drive.google.com/file/d/1zQFrAh4C26MJQaHclV3ljngCAySSq7SH/view?usp=sharing">zip file</a>.
        <br>
        All accepted papers are going to be published in the <a style="color:#1a1aff;font-weight:400;" href="https://openaccess.thecvf.com/ACCV2024_workshops">ACCV 2024 Workshop proceedings</a> and <a style="color:#1a1aff;font-weight:400;" href="https://link.springer.com/conference/accv">Springer ACCV 2024 Workshop LNCS</a>.
        <br>
        <u>Important note: PDF files must be under 20MB.</u>
      </p>
  </div>
</div>


<p><br /></p>

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Call for papers announced</td>
          <td>July 9, 2024</td>
        </tr>
        <tr>
          <td>Paper submission deadline</td>
          <td><b>September 14, 2024</b></td>
        </tr>
        <tr>
          <td>Notifications to accepted papers</td>
          <td>September 20, 2024</td>
        </tr>
        <tr>
          <td>Paper camera ready</td>
          <td>September 30, 2024</td>
        </tr>
        <tr>
          <td>Workshop date</td>
          <td><b>December 8, 2024</b></td>
        </tr>
      
      </tbody>
    </table>
  </div>
</div>

<p><br /></p>
<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
  </div>
</div>

<div class="row">
  <div class="col-md-2">
    <!-- <a href="https://ukcheolshin.github.io/"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/ukcheolshin.jpg" /></a> -->
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://ukcheolshin.github.io/">Dr. Ukcheol Shin (Carnegie Mellon University)</a></b> Dr. Ukcheol Shin is a postdoctoral researcher at the Robotics Institute of Carnegie Mellon University. His research focuses on developing a robust robot vision system that can perceive and navigate the dynamic world, even in challenging conditions, with a particular interest in self-supervised learning of 3D geometry and multi-sensor fusion. Dr. Shin has made significant contributions to the field of multispectral imaging, with a focus on topics such as thermal image segmentation and depth estimation on thermal images. Furthermore, he is one of the authors of the MS2 dataset, a valuable resource for the research community.
    </p>
  </div>
</div>
<p><br /></p>

<div class="row">
  <div class="col-md-2">
    <!-- <a href="https://stl.yonsei.ac.kr/"><img class="people-pic" style="float:left;margin-right:50px;" src="static/img/people/yonsei_logo.png" /></a> -->
  </div>
  <div class="col-md-10">
    <p>
      <b><a href="https://stl.yonsei.ac.kr/">To Be Announced.</a></b> 
    </p>
  </div>
</div>


<!-- <p><br /></p>
<div class="row" id="accepted">
  <div class="col-xs-12">
    <h2>Accepted Papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-md-12">
    <table>
      <tbody> 
      <tr><td><a href="https://arxiv.org/abs/2212.01558">#1. PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="gray">Minghua Liu, Yinhao Zhu, Hong Cai, Shizhong Han, Zhan Ling, Fatih Porikli, Hao Su</font></td></tr>
    </tbody></table>
  </div>

</div> -->


<p><br /></p>
<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Schedule (Hanoi, Vietnam / Indochina Time Zone (ICT) (*GMT +7))</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
     <table class="table table-striped">
      <thead>
        <tr>
          <th>Time</th>
          <th>Particulars</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>10:00 AM - 10:15 AM</td>
          <td>Welcome</td>
        </tr>
        <tr>
          <td>10:15 AM - 10:45 AM</td>
          <td>Opening Talk by Prof. Shiho Kim, Yonsei University, Seoul, Korea</td>
        </tr>
        <tr>
          <td>10:50 AM - 11:35 AM</td>
          <td>Invited Talk by Dr. Ukcheol Shin, Carnegie Mellon University, Pittsburgh, PA, USA</td>
        </tr>
        <tr>
          <td></td>
          <td><b>Paper Session 1</b></td>
        </tr>
        <tr>
          <td>11:40 AM - 12:00 PM</td>
          <td>Accepted Papers Presentation #1</td>
        </tr>
        <tr>
          <td>12:05 PM - 12:25 PM</td>
          <td>Accepted Papers Presentation #2</td>
        </tr>
        <tr>
          <td>12:30 PM - 01:30 PM</td>
          <td>Coffee Break</td>
        </tr>
        <tr>
          <td>01:30 PM - 02:15 PM</td>
          <td>Invited Talk</td>
        </tr>
        <tr>
          <td></td>
          <td><b>Paper Session 2</b></td>
        </tr>
        <tr>
          <td>02:20 PM - 02:40 PM</td>
          <td>Accepted Papers Presentation #3</td>
        </tr>
        <tr>
          <td>02:45 PM - 03:05 PM</td>
          <td>Accepted Papers Presentation #4</td>
        </tr>
        <tr>
          <td>03:05 PM - 03:10 PM</td>
          <td>Concluding remarks</td>
        </tr>
      </tbody>
    </table>
  </div>
</div>

<p><br /></p>

<div class="row" id="contact">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      <li><a href="https://ynalcakan.github.io/">Dr. Yağız Nalçakan</a> - Seamless Trans-X Lab - Yonsei University</li>
      <li><a href="https://stl.yonsei.ac.kr/">Yeongwan Jin</a> - Seamless Trans-X Lab - Yonsei University</li>
      <li><a href="https://stl.yonsei.ac.kr/">Hyeongjin Ju</a> - Seamless Trans-X Lab - Yonsei University</li>
      <li><a href="https://stl.yonsei.ac.kr/">Hanbin Song</a> - Seamless Trans-X Lab - Yonsei University</li>
    </p>
  </div>
</div>

<p><br /></p>

<div class="row" id="contact">
  <div class="col-xs-12">
    <h2>Program Committee</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      <li><a href="https://stl.yonsei.ac.kr/theme/s007/index/sub1_2.php">Prof. Shiho Kim (program chair)</a> - Yonsei University</li>
      <li>Prof. Guofa Li - Chongqing University</li>
      <li>Prof. Chih-Hsien Hsia - National Ilan University</li>
      <li>Dr. Ashutosh Mishra - Birla Institute of Technology and Science</li>
      <li>Dr. Jianwu Fang - Chang'an University</li>
      <li>Dr. Jifeng Shen - Jiangsu University</li>
      <li>Dr. Di Yuan - Xidian University</li>
      
    </p>
  </div>
</div>

<p><br /></p>

<div class="row" id="contact">
  <div class="col-xs-12">
    <h2>Contact</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      To contact the organizers please use <a href="mailto:multispectral4ra@outlook.com">multispectral4ra@outlook.com</a>
    </p>
  </div>
</div>
<p><br /></p>

<hr />

<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgments</h2>
  </div>
</div>
<p><a name="/acknowledgements"></a></p>
<div class="row">
  <div class="col-xs-12">
    <p>
      Thanks to <span style="color:#1a1aff;font-weight:400;"> <a href="https://visualdialog.org/">visualdialog.org</a></span> and <span style="color:#1a1aff;font-weight:400;"> <a href="https://languagefor3dscenes.github.io/"> L3DS workshop team</a></span> for the webpage format.
    </p>
  </div>
  <div class="col-xs-3" style="width: 200px; height: 150px; display: flex; align-items: center; justify-content: center;">
    <a href="https://www.yonsei.ac.kr/">
      <img src="static/img/site/yonsei-university-logo.jpg"/>
    </a>
  </div>

  <div class="col-xs-3" style="width: 150px; height: 150px; display: flex; align-items: center; justify-content: center;">
    <a href="https://stl.yonsei.ac.kr/">
      <img src="static/img/site/stl-logo-blue.png"/>
    </a>
  </div>
</div>
<br>
<br>
<br>
      </div>
    </div>

  </body>
</html>
